---
---

@article{FRAI2021,
  author={{Kan Li and Jos{\'{e}} C. Pr{\'{i}}ncipe}},	 
  title={Biologically-Inspired Pulse Signal Processing for Intelligence at the Edge},      	
  journal={Frontiers in Artificial Intelligence},      	
  volume={4},      
  pages={129},     	
  year={2021},      	  
  url={https://www.frontiersin.org/article/10.3389/frai.2021.568384},       
  doi={10.3389/frai.2021.568384},      
  issn={2624-8212},      
  abstract={There is an ever-growing mismatch between the proliferation of data-intensive, power-hungry deep learning solutions in the machine learning (ML) community and the need for agile, portable solutions in resource-constrained devices, particularly for intelligence at the edge. In this paper, we present a fundamentally novel approach that leverages data-driven intelligence with biologically-inspired efficiency. The proposed Sparse Embodiment Neural-Statistical Architecture (SENSA) decomposes the learning task into two distinct phases: a training phase and a hardware embedment phase where prototypes are extracted from the trained network and used to construct fast, sparse embodiment for hardware deployment at the edge. Specifically, we propose the Sparse Pulse Automata via Reproducing Kernel (SPARK) method, which first constructs a learning machine in the form of a dynamical system using energy-efficient spike or pulse trains, commonly used in neuroscience and neuromorphic engineering, then extracts a rule-based solution in the form of automata or lookup tables for rapid deployment in edge computing platforms. We propose to use the theoretically-grounded unifying framework of the Reproducing Kernel Hilbert Space (RKHS) to provide interpretable, nonlinear, and nonparametric solutions, compared to the typical neural network approach. In kernel methods, the explicit representation of the data is of secondary nature, allowing the same algorithm to be used for different data types without altering the learning rules. To showcase SPARK’s capabilities, we carried out the first proof-of-concept demonstration on the task of isolated-word automatic speech recognition (ASR) or keyword spotting, benchmarked on the TI-46 digit corpus. Together, these energy-efficient and resource-conscious techniques will bring advanced machine learning solutions closer to the edge.},
  HTML={https://www.frontiersin.org/articles/10.3389/frai.2021.568384},
  pdf={frai-04-568384.pdf},
  selected={true}
}



@article{FBF,
  author={{Kan Li and Jos{\'{e}} C. Pr{\'{i}}ncipe}},	 
  journal={IEEE Transactions on Signal Processing}, 
  title={Functional Bayesian Filter}, 
  year={2021},
  volume={},
  number={},
  pages={},
  doi={10.1109/TSP.2021.3132277},
  abstract={We present a general nonlinear Bayesian filter for high-dimensional state estimation using the theory of reproducing kernel Hilbert space (RKHS). By applying the kernel method and the representer theorem to perform linear quadratic estimation in a functional space, we derive a Bayesian recursive state estimator for a general nonlinear dynamical system in the original input space. Unlike existing nonlinear extensions of the Kalman filter where the system dynamics are assumed known, the state-space representation for the Functional Bayesian Filter (FBF) is completely learned online from measurement data in the form of an infinite impulse response (IIR) filter or recurrent network in the RKHS, with universal approximation property. Using a positive definite kernel function satisfying Mercer's conditions to compute and evolve information quantities, the FBF exploits both the statistical and time-domain information about the signal, extracts higher-order moments, and preserves the properties of covariances without the ill effects due to conventional arithmetic operations. We apply this novel kernel adaptive filtering (KAF) to recurrent network training, chaotic time-series estimation and cooperative filtering using Gaussian and non-Gaussian noises, and inverse kinematics modeling. Simulation results show FBF outperforms existing Kalman-based algorithms.},
  HTML={https://ieeexplore.ieee.org/document/9633213},
  pdf={FBF_IEEEtsp_Final.pdf},
  selected={true}
}

@inproceedings{LVEDP21,
  author={{Kan Li, Diego Pava, Arash Andalib, and Kaustubh Kale}},	 
  booktitle={Heart Failure Society of America (HFSA) Annual Scientific Meeting},
  title={Non-invasive Assessment of Elevated LVEDP Using a Small Portable Device: Design for Telemonitoring}, 
  year={2021},
  volume={},
  number={},
  pages={},
  location = {Denver, CO},
  month={Sep},
  abstract={Left ventricular end-diastolic pressure (LVEDP) provides crucial information on the LV operating compliance and is a key marker for congestive heart failure and pulmonary hypertension. The diagnosis and monitoring of the left-sided filling pressure often requiring invasive procedures. HEMOTAG, is a small portable device that uses micro-sensors to capture cardiac vibrations and electrocardiogram (ECG), transduced via thoracic electrodes. It is a viable option to measure cardiac time intervals (CTIs), surrogate markers of hemodynamics and intracardiac pressure. In this study, diastolic-to-systolic time ratio (DSR) and systolic time ratio (STR) along with the patient’s age, height, and weight were assessed as valid markers for elevated LVEDP, compared against left heart catheterization LVEDP measurement.},
  audio={HFSA_LVEDP.mp3},
  HTML={https://www.sciencedirect.com/science/article/abs/pii/S1071916422001397},
  pdf={HFSA 2021 LVEDP.pdf},
  selected={true}
}

@inproceedings{DM21,
  author={{Diego Pava, Arash Andalib, Kan Li, and Kaustubh Kale}},	 
  booktitle={Heart Failure Society of America (HFSA) Annual Scientific Meeting},
  title={A Novel Non-Invasive Device for Screening and Optimized Management to Improve Heart Failure Outcomes in Patients with Diabetes Mellitus}, 
  year={2021},
  volume={},
  number={},
  pages={},
  location = {Denver, CO},
  month={Sep},
  abstract={Evidence shows diabetes mellitus (DM) is major independent risk factor for several cardiovascular disorders including heart failure (HF). Large, randomized clinical trials for screening and revascularization of stable macrovascular disease in diabetics, have failed to demonstrate a significant reduction in cardiac events and HF episodes. Studies have demonstrated that early detection of left ventricular dysfunction and prevention of microvascular complications through glycemic control in diabetes patients is a critical mechanism for reducing the incidence and severity of left ventricular dysfunction and HF.  There is a need for a non-invasive, affordable, accurate, absolute and actionable method to facilitate optimized management of diabetes patients across the continuity of care. HEMOTAG, is a small portable device that uses micro-sensors to capture cardiac vibrations and electrocardiogram, transduced via thoracic electrodes. It is a viable option to measure cardiac time intervals (CTIs), surrogate markers for measurements of left ventricular dysfunction.},
  audio={HFSA_DM.mp3},
  HTML={https://www.sciencedirect.com/science/article/abs/pii/S1071916422001452},
  pdf={HFSA 2021 LVEDP.pdf},
  selected={true}
}

@misc{https://doi.org/10.48550/arxiv.2001.00265, 
  author = {{Kan Li and Jos{\'{e}} C. Pr{\'{i}}ncipe}},
  title = {Fast Estimation of Information Theoretic Learning Descriptors using Explicit Inner Product Spaces},
  publisher = {arXiv},
  year = {2020},
  abstract={Kernel methods form a theoretically-grounded, powerful and versatile framework to solve nonlinear problems in signal processing and machine learning. The standard approach relies on the \emph{kernel trick} to perform pairwise evaluations of a kernel function, leading to scalability issues for large datasets due to its linear and superlinear growth with respect to the training data. Recently, we proposed \emph{no-trick} (NT) kernel adaptive filtering (KAF) that leverages explicit feature space mappings using data-independent basis with constant complexity. The inner product defined by the feature mapping corresponds to a positive-definite finite-rank kernel that induces a finite-dimensional reproducing kernel Hilbert space (RKHS). Information theoretic learning (ITL) is a framework where information theory descriptors based on non-parametric estimator of Renyi entropy replace conventional second-order statistics for the design of adaptive systems. An RKHS for ITL defined on a space of probability density functions simplifies statistical inference for supervised or unsupervised learning. ITL criteria take into account the higher-order statistical behavior of the systems and signals as desired. However, this comes at a cost of increased computational complexity. In this paper, we extend the NT kernel concept to ITL for improved information extraction from the signal without compromising scalability. Specifically, we focus on a family of fast, scalable, and accurate estimators for ITL using explicit inner product space (EIPS) kernels. We demonstrate the superior performance of EIPS-ITL estimators and combined NT-KAF using EIPS-ITL cost functions through experiments.},
  HTML = {https://arxiv.org/abs/2001.00265},
  doi = {10.48550/ARXIV.2001.00265}, 
}

@misc{https://doi.org/10.48550/arxiv.1912.04530, 
  author = {{Kan Li and Jos{\'{e}} C. Pr{\'{i}}ncipe}},
  title = {No-Trick (Treat) Kernel Adaptive Filtering using Deterministic Features},
  publisher = {arXiv},
  year = {2019},
  abstract={Kernel methods form a powerful, versatile, and theoretically-grounded unifying framework to solve nonlinear problems in signal processing and machine learning. The standard approach relies on the kernel trick to perform pairwise evaluations of a kernel function, which leads to scalability issues for large datasets due to its linear and superlinear growth with respect to the training data. A popular approach to tackle this problem, known as random Fourier features (RFFs), samples from a distribution to obtain the data-independent basis of a higher finite-dimensional feature space, where its dot product approximates the kernel function. Recently, deterministic, rather than random construction has been shown to outperform RFFs, by approximating the kernel in the frequency domain using Gaussian quadrature. In this paper, we view the dot product of these explicit mappings not as an approximation, but as an equivalent positive-definite kernel that induces a new finite-dimensional reproducing kernel Hilbert space (RKHS). This opens the door to no-trick (NT) online kernel adaptive filtering (KAF) that is scalable and robust. Random features are prone to large variances in performance, especially for smaller dimensions. Here, we focus on deterministic feature-map construction based on polynomial-exact solutions and show their superiority over random constructions. Without loss of generality, we apply this approach to classical adaptive filtering algorithms and validate the methodology to show that deterministic features are faster to generate and outperform state-of-the-art kernel methods based on random Fourier features.},
  HTML = {https://arxiv.org/abs/1912.04530},
  doi = {10.48550/ARXIV.1912.04530}, 
}

 @INPROCEEDINGS{8489555,
  author={{Kan Li and Jos{\'{e}} C. Pr{\'{i}}ncipe}},
  booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Surprise-Novelty Information Processing for Gaussian Online Active Learning (SNIP-GOAL)}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IJCNN.2018.8489555},
  abstract={In this paper, we propose a novel, combined surprise-novelty approach to online active learning for kernel adaptive filters. Surprise and novelty criteria have always been used individually in designing sparse kernel machines. While closely related, they are in fact two distinct concepts. In this paper, we highlight the key differences between surprise and novelty, define quantitative measures, and propose a unifying framework that leverages the complementary properties of the two concepts combined. We test the information theoretic approach of designing sparse kernel adaptive filters using the surprise-novelty information processing for Gaussian online active learning (SNIP-GOAL) on the task of nonlinear chaotic time series prediction. The proposed method outperforms existing algorithms using the measures individually. Results show that combining surprise and novelty can be advantageous in terms of efficiency and performance. Leveraging both measures allows the system to be not only sparse but also generalizes better.},
  HTML={https://ieeexplore.ieee.org/document/8489555}}
 
 @INPROCEEDINGS{8461584,
  author={Singh, Rishabh and Li, Kan and Principe, Jose C.},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Nearest-Instance-Centroid-Estimation Linear Discriminant Analysis (NICE LDA)}, 
  year={2018},
  volume={},
  number={},
  pages={2846-2850},
  doi={10.1109/ICASSP.2018.8461584}
  abstract={We propose a novel cascaded classification technique called the Nearest Instance Centroid Estimation (NICE) LDA algorithm. Our algorithm (inspired from NICE KLMS) performs a cascade combination of two weak classifiers - threshold based class-wise clustering and linear discriminant classification to achieve state-of-the-art results on various high dimensional UCI datasets. We show how our method is more robust towards skewed data and computationally more efficient than previous methods of combining clustering with classification techniques. We also develop an efficient aggregation method based on instance based learning that implements this cascade combination of classifiers in a much simpler manner computationally. We demonstrate that our method of data clustering and LDA implementation, while introducing only one free parameter, leads to results that are similar and often better than those achieved by the state-of-the-art kernel RBF SVMs.},
  HTML={https://ieeexplore.ieee.org/document/8461584}}
